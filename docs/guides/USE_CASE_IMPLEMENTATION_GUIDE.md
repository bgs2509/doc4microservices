# AI-Powered Project Generation Guide

This guide provides comprehensive instructions for creating complete, production-ready microservices applications using the AI agents framework. All implementations follow the standardized project structure and architectural patterns documented in [../../CLAUDE.md](../../CLAUDE.md).

**NEW APPROACH**: This guide covers the **AI-first project generation workflow** where users create new repositories and AI generates complete applications with proper structure.

## Table of Contents

- [AI-First Development Workflow](#ai-first-development-workflow)
- [Generated Project Structure](#generated-project-structure)
- [AI Generation Process](#ai-generation-process)
- [Implementation Guidelines](#implementation-guidelines)
- [Quality Standards](#quality-standards)
- [Deployment and Production](#deployment-and-production)
- [Common Patterns](#common-patterns)
- [Validation Checklist](#validation-checklist)

---

## ⚠️ MANDATORY ARCHITECTURE CONSTRAINTS

**Before generating any application, AI agents MUST comply with these non-negotiable constraints:**

> **⚠️ MANDATORY COMPLIANCE**: All constraints are defined in the [canonical architecture documentation](ARCHITECTURE_GUIDE.md). This section provides implementation-specific guidance.

### 1. **Architecture Compliance (MANDATORY)**
- **Foundation**: Follow the [Improved Hybrid Approach architecture](ARCHITECTURE_GUIDE.md)
- **Data Access**: HTTP-only communication with data services
- **Service Separation**: Each service type in separate containers
- **Project Structure**: All source code in `src/` folder, Dockerfiles in service folders

### 2. **Development Standards**
- **Commands**: Use [canonical development commands](DEVELOPMENT_COMMANDS.md)
- **Technology**: Follow [complete technology specifications](LINKS_REFERENCE.md#core-documentation)
- **Architecture**: Follow [comprehensive architecture guide](ARCHITECTURE_GUIDE.md)
- **Naming**: Follow [../architecture/naming_conventions.mdc](../architecture/naming_conventions.mdc)
- **Patterns**: See [../INDEX.md](../INDEX.md) for service-specific implementation patterns

**Violation of these constraints will result in non-functional applications. This guide provides compliant generation patterns.**

---

## AI-First Development Workflow

### Step 1: User Creates New Repository
```bash
# User creates new repository for their project
mkdir my_awesome_project
cd my_awesome_project
git init
```

### Step 2: AI Reads Documentation Project
AI agents access this documentation project to understand:
- Architectural patterns and constraints
- Service templates and implementation rules
- Quality standards and testing patterns
- Deployment and configuration patterns

### Step 3: AI Generates Complete Application
Using the ai_agents framework, AI generates:
- Complete project structure with `src/` folder organization
- All microservices with proper separation
- Docker Compose configuration in root
- Environment configuration and documentation
- Testing infrastructure and examples

### Step 4: Deploy and Iterate
```bash
# Generated by AI, executed by user
cp .env.example .env
# Edit .env with your configuration
docker-compose up -d
```

---

## Generated Project Structure

AI agents generate projects following this standardized structure:

> **📋 AUTHORITATIVE PROJECT STRUCTURE**: See [../reference/PROJECT_STRUCTURE.md](../reference/PROJECT_STRUCTURE.md) for the complete, detailed project structure guide with explanations and setup instructions.

### Key Structure Principles

1. **Root-Level Configuration**: Docker Compose, environment, and project configs in root
2. **Source Code Organization**: All code in `src/` with clear separation
3. **Service-Specific Dockerfiles**: Each service has its own Dockerfile in its folder
4. **Shared Components**: Common code in `src/shared/` and `src/config/`
5. **Comprehensive Testing**: Unit and integration tests with proper fixtures

---

## AI Generation Process

### Phase 1: Business Validation
AI uses the `ai_agents/business_validation/` *(or `.framework/ai_agents/business_validation/` when used as submodule)* framework to:
1. **Feasibility Check**: Validate if business idea fits the architecture
2. **Domain Classification**: Identify business patterns and optimal allocation
3. **Constraint Validation**: Ensure architectural compliance

### Phase 2: Service Mapping
AI uses the `ai_agents/mapping/` *(or `.framework/ai_agents/mapping/` when used as submodule)* framework to:
1. **Service Allocation**: Map business functions to specific services
2. **Data Flow Design**: Define PostgreSQL vs MongoDB usage
3. **Integration Patterns**: Specify service communication

### Phase 3: Code Generation
AI uses the `ai_agents/generators/` *(or `.framework/ai_agents/generators/` when used as submodule)* framework to:
1. **Template Selection**: Choose appropriate service templates
2. **Variable Substitution**: Fill templates with business-specific data
3. **Code Assembly**: Generate complete implementations

### Phase 4: Quality Validation
AI uses the `ai_agents/validation/` *(or `.framework/ai_agents/validation/` when used as submodule)* framework to:
1. **Architecture Compliance**: Verify HTTP-only data access, service separation
2. **Code Quality**: Check type hints, error handling, naming conventions
3. **Integration Testing**: Ensure service communication works

### Phase 5: Deployment Generation
AI uses the `ai_agents/deployment/` *(or `.framework/ai_agents/deployment/` when used as submodule)* framework to:
1. **Docker Compose**: Generate complete infrastructure configuration
2. **Environment Setup**: Create secure configuration templates
3. **Deployment Scripts**: Generate automation and health checks

---

## Implementation Guidelines

### Service Implementation Standards

#### 1. **FastAPI Services (`src/services/api_service/`)**
```python
# Generated main.py structure
"""
API Service - FastAPI Business Logic Implementation
Generated for: {{business_domain}}
"""

import asyncio
import logging
from contextlib import asynccontextmanager

import httpx
from fastapi import FastAPI, HTTPException
import structlog

# Service-specific imports from src/shared/
from ...shared.dtos import {{model_imports}}
from ...config.settings import Settings

# HTTP-only data access via data services
class DataServiceClient:
    def __init__(self):
        self.postgres_url = "http://db_postgres_service:8001"
        self.mongo_url = "http://db_mongo_service:8002"
```

#### 2. **Aiogram Bot Services (`src/services/bot_service/`)**
```python
# Generated main.py structure
"""
Bot Service - Aiogram Telegram Bot Implementation
Generated for: {{business_domain}}
"""

import asyncio
import logging

from aiogram import Bot, Dispatcher
from aiogram.types import Message
import structlog

# HTTP-only communication with API service
class BotService:
    def __init__(self):
        self.api_url = "http://api_service:8000"
        # No direct database access
```

#### 3. **Worker Services (`src/services/worker_service/`)**
```python
# Generated main.py structure
"""
Worker Service - AsyncIO Background Workers
Generated for: {{business_domain}}
"""

import asyncio
import logging

import aio_pika
import structlog

# Event-driven processing with HTTP data access
class WorkerService:
    def __init__(self):
        self.postgres_url = "http://db_postgres_service:8001"
        self.mongo_url = "http://db_mongo_service:8002"
        # Event handling via RabbitMQ
```

### Docker Configuration Standards

#### 1. **Service Dockerfiles (`src/services/*/Dockerfile`)**
```dockerfile
FROM python:3.12-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy service-specific requirements
COPY src/services/{{service_name}}/requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

# Copy shared modules
COPY src/shared/ ./shared/
COPY src/config/ ./config/

# Copy service code
COPY src/services/{{service_name}}/ ./

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

CMD ["python", "main.py"]
```

#### 2. **Root Docker Compose (`docker-compose.yml`)**
```yaml
# Generated by AI in project root
version: '3.8'

services:
  # Infrastructure Services
  postgres:
    image: postgres:16
    environment:
      POSTGRES_DB: {{project_name}}_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres123
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - app_network

  # Data Services
  db_postgres_service:
    build:
      context: "."
      dockerfile: "./src/services/db_postgres_service/Dockerfile"
    environment:
      DATABASE_URL: postgresql://postgres:postgres123@postgres:5432/{{project_name}}_db
    ports:
      - "8001:8000"
    depends_on:
      - postgres
    networks:
      - app_network

  # Business Services
  api_service:
    build:
      context: "."
      dockerfile: "./src/services/api_service/Dockerfile"
    environment:
      POSTGRES_SERVICE_URL: http://db_postgres_service:8000
      MONGO_SERVICE_URL: http://db_mongo_service:8000
    ports:
      - "8000:8000"
    depends_on:
      - db_postgres_service
      - db_mongo_service
    networks:
      - app_network

networks:
  app_network:
    driver: bridge

volumes:
  postgres_data:
```

---

## Quality Standards

### Code Quality Requirements

1. **Type Annotations**: 100% type coverage for all functions
2. **Error Handling**: Comprehensive error handling with structured logging
3. **HTTP-Only Data Access**: No direct database imports in business services
4. **Service Separation**: Each service type in separate containers
5. **Security**: OAuth2/JWT, input validation, no hardcoded secrets

### Testing Requirements

1. **Unit Tests**: 100% coverage for critical business logic paths
2. **Integration Tests**: Real service communication via testcontainers
3. **End-to-End Tests**: Complete workflows across services
4. **Performance Tests**: Load testing for expected traffic

### Documentation Requirements

1. **Project README**: Clear setup and usage instructions
2. **API Documentation**: OpenAPI/Swagger for all endpoints
3. **Architecture Overview**: Service communication and data flow
4. **Deployment Guide**: Production deployment instructions

---

## Deployment and Production

### Pre-Deployment Checklist

- [ ] All tests pass with required coverage
- [ ] Docker images build successfully
- [ ] Environment variables documented and validated
- [ ] Health checks implemented and working
- [ ] Security scan passes (bandit, safety)
- [ ] Load testing completed
- [ ] Documentation complete and accurate

### Production Environment

- [ ] SSL/TLS certificates configured
- [ ] Secrets management implemented
- [ ] Database backups automated
- [ ] Log aggregation configured
- [ ] Monitoring dashboards created
- [ ] Alerting rules defined
- [ ] Disaster recovery plan documented

---

## Common Patterns

### Example Business Domain Mappings

#### E-commerce Application
```yaml
postgresql_entities: ["users", "products", "orders", "payments"]
mongodb_collections: ["product_reviews", "user_behavior", "analytics"]
api_endpoints: ["GET /products", "POST /orders", "GET /users/{id}"]
bot_commands: ["/products", "/order_status", "/support"]
worker_tasks: ["process_payments", "send_notifications", "generate_reports"]
```

#### Project Management Tool
```yaml
postgresql_entities: ["users", "projects", "tasks", "time_entries"]
mongodb_collections: ["activity_logs", "file_attachments", "analytics"]
api_endpoints: ["GET /projects", "POST /tasks", "PUT /tasks/{id}"]
bot_commands: ["/create_task", "/my_tasks", "/deadlines"]
worker_tasks: ["send_reminders", "generate_reports", "backup_data"]
```

### Data Service Communication Patterns

```python
# HTTP-only communication example
class BusinessService:
    async def get_user_data(self, user_id: str) -> UserData:
        """Get user data via PostgreSQL service"""
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{self.postgres_url}/api/v1/users/{user_id}"
            )
            response.raise_for_status()
            return UserData(**response.json())

    async def track_analytics(self, event_data: EventData) -> None:
        """Track analytics via MongoDB service"""
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.mongo_url}/api/v1/events",
                json=event_data.dict()
            )
            response.raise_for_status()
```

---

## Validation Checklist

### ✅ Project Structure Validation

- [ ] All required directories exist in `src/` structure
- [ ] Dockerfiles present in each service folder
- [ ] Docker Compose in project root
- [ ] Environment configuration files present
- [ ] Shared components properly organized

### ✅ Service Implementation Validation

- [ ] Health check endpoints implemented
- [ ] HTTP-only data access pattern followed
- [ ] No direct database connections in business services
- [ ] Proper async/await usage
- [ ] Structured logging configured

### ✅ Architecture Compliance Validation

- [ ] Service type separation enforced
- [ ] Data services accessible via HTTP on ports 8001, 8002
- [ ] RabbitMQ event communication working
- [ ] Redis caching functional
- [ ] Naming conventions followed (underscore_only)

### ✅ Quality Validation

- [ ] Type annotations on all functions
- [ ] Error handling comprehensive
- [ ] Security measures implemented
- [ ] Performance requirements met
- [ ] Code quality tools configured and passing

---

## Conclusion

The **AI-first project generation workflow** enables rapid creation of production-ready microservices applications. Key success factors:

1. **AI Framework Utilization**: Use the complete `ai_agents/` *(or `.framework/ai_agents/` when used as submodule)* framework for validation, mapping, generation, and deployment
2. **Structure Compliance**: Follow the standardized `src/` folder organization with root-level configuration
3. **Architecture Adherence**: HTTP-only data access, service separation, event-driven communication
4. **Quality Focus**: Comprehensive testing, security, monitoring, and documentation

**Estimated Generation Time:** 5-15 minutes for complete application generation vs 2-4 days for manual implementation.

**Next Steps:**
1. Create new repository for your project
2. Use AI agents with this documentation project as context
3. Generate complete application following this guide
4. Deploy using generated Docker Compose configuration
5. Customize and extend for your specific business needs

---

**🚀 Ready to generate your first AI-powered microservices application?** Create a new repository and start collaborating with AI using this knowledge base!