---
description: Asyncio standard for Python microservices, focuses on clean architecture, background task lifecycle management, asynchronous resource access, and avoiding event loop conflicts.
globs: ["src/**/*.py"]
alwaysApply: true
---

### Title
Asyncio Rules (Python, Worker Services)

### Version and Date
- Version: v2.0.0
- Updated: 2025-09-19
- Owner: rules/architecture

### Purpose
Define a unified standard for using `asyncio` in background microservices (worker services), ensuring proper lifecycle management, efficient use of asynchronous resources (e.g., RabbitMQ, PostgreSQL, Redis), and preventing conflicts with other frameworks.

### Scope
- Covers: asynchronous service lifecycle management, task startup and shutdown, use of asynchronous libraries, event loop isolation, logging integration, Redis integration, RabbitMQ integration, and testing requirements.
- Excludes: does not cover `FastAPI` or `AIOgram` rules (see `fastapi_rules.mdc`, `aiogram_rules.mdc`), which manage their own event loops.

### Terms and Definitions
- **Event Loop**: Event loop that manages the execution of asynchronous tasks.
- **Worker Service**: Microservice that performs background tasks, such as queue processing or file processing, and is not a web server.
- **Request ID**: Cross-cutting request identifier for full tracing (from `logging_rules.mdc`).
- **Redis Dependency**: Redis client instance managed within the asyncio event loop for caching and idempotency.
- **RabbitMQ Dependency**: RabbitMQ client instance managed within the asyncio event loop for message publishing and consuming.

### Rules
1) **Lifecycle Management and Event Loop Ownership**
   - **MUST:** Use `asyncio.run(main())` in the main entry point to start an asynchronous application in its own dedicated event loop.
   - **MUST:** Start and stop all asynchronous dependencies (RabbitMQ, Redis, PostgreSQL connections) within the `main()` async function.
   - **MUST:** Call `setup_logging()` exactly once at the beginning of the `main()` function after configuration is loaded.
   - **SHOULD:** Handle termination signals (`SIGTERM`, `SIGINT`) for proper shutdown of asynchronous tasks.
   - **EVENT LOOP BOUNDARY:** AsyncIO worker services MUST run in separate processes from FastAPI services to avoid event loop conflicts.

2) **Event Loop Isolation and Service Boundaries**
   - **MUST:** Ensure that `zd_file_handling` and `zd_pg_file_record` services that use `asyncio.run()` do not contain imports or code from `FastAPI` or `AIOgram`.
   - **MUST:** `FastAPI` and `AIOgram` must manage their own event loops and must not be started via `asyncio.run()` in the main file.
   - **MUST:** Run AsyncIO worker services as separate processes/containers from FastAPI services to avoid event loop conflicts.
   - **MUST NOT:** Mix FastAPI handlers with AsyncIO worker tasks in the same process - this creates competing event loop claims.

3) **Asynchronous Operations**
   - **MUST:** Use asynchronous versions of libraries (`aio-pika`, `asyncpg`, `redis.asyncio`).
   - **SHOULD:** Avoid blocking calls (`time.sleep()`, `requests.get()`) in asynchronous code. If a blocking operation is necessary, it should be wrapped in `asyncio.to_thread()` or run in a separate thread/process.
   - **MUST:** Use `async def` for all functions containing `await`.

4) **Task Management**
   - **SHOULD:** Use `asyncio.create_task()` to start background tasks.
   - **SHOULD:** Use `asyncio.gather()` or `asyncio.TaskGroup` for parallel execution of multiple asynchronous operations.

5) **External service integration**
   - **MUST:** Follow Redis integration patterns as defined in `redis_rules.mdc` for caching and idempotency.
   - **MUST:** Follow RabbitMQ integration patterns as defined in `rabbitmq_rules.mdc` for messaging.
   - **MUST:** Initialize external clients (Redis, RabbitMQ) once in `main()` function and store in global context.
   - **MUST:** Pass external clients as dependencies to worker functions and tasks.
   - **MUST:** Ensure all external service operations are compatible with asyncio event loop.

6) **Logging Integration**
   - **MUST:** Follow logging patterns as defined in `logging_rules.mdc`.
   - **MUST:** Generate Request ID for each worker task using `generate_request_id(prefix, **context)`.
   - **MUST:** Use `set_request_id()` to propagate Request ID context throughout the worker lifecycle.
   - **SHOULD:** Log worker lifecycle events (startup, shutdown, task processing) with proper Request ID context.

7) **Configuration Management**
   - **MUST:** Use `pydantic.BaseSettings` for configuration management in `src/core/config.py`.
   - **MUST:** Load configuration before calling `setup_logging()`.

8) **Testing Requirements**
   - **MUST:** Follow testing requirements from `testing-standards.mdc` for AsyncIO worker services.

### Priorities and Compatibility
- Depends on: `../architecture/ms_best_practices_rules.mdc` (system-wide standard), `../observability/logging_rules.mdc` (observability), `../infrastructure/redis_rules.mdc` (Redis integration), `../infrastructure/rabbitmq_rules.mdc` (messaging), `../quality/testing-standards.mdc` (testing requirements).
- Does not duplicate: rules for `FastAPI` or `AIOgram`, Redis patterns (see `../infrastructure/redis_rules.mdc`), RabbitMQ patterns (see `../infrastructure/rabbitmq_rules.mdc`).
- Conflicts: none; explicitly separated from `FastAPI` and `AIOgram`.

### Examples
```python
# Example main file for Worker Service with Redis and RabbitMQ integration
import asyncio
import signal
from contextlib import suppress
from typing import Any

from src.core.config import settings
from src.core.logging import setup_logging, logger, generate_request_id, set_request_id
from src.adapters.rabbitmq.photo_event_publisher import RabbitMQClient
from src.adapters.redis.idempotency_client import RedisClient

# Global client instances
redis_client: RedisClient | None = None
rabbitmq_client: RabbitMQClient | None = None

async def main():
    global redis_client, rabbitmq_client

    # 1. Load configuration and setup logging
    setup_logging()
    request_id = generate_request_id("worker_startup")
    set_request_id(request_id)
    logger.info("worker_startup service=file_handling_worker")

    # 2. Start asynchronous dependencies
    redis_client = RedisClient("redis://localhost:6379")
    await redis_client.connect()
    logger.info("dependencies_connected redis=connected")

    rabbitmq_client = RabbitMQClient("amqp://guest:guest@localhost:5672/")
    await rabbitmq_client.connect()
    logger.info("dependencies_connected rabbitmq=connected")

    # 3. Setup signal handlers before creating tasks
    loop = asyncio.get_event_loop()
    consumer_task = None

    def signal_handler(signum):
        logger.info(f"signal_received signal={signum}")
        if consumer_task:
            consumer_task.cancel()

    loop.add_signal_handler(signal.SIGINT, lambda: signal_handler(signal.SIGINT))
    loop.add_signal_handler(signal.SIGTERM, lambda: signal_handler(signal.SIGTERM))

    # 4. Start background tasks
    consumer_task = asyncio.create_task(rabbitmq_client.start_consuming())
    logger.info("background_tasks_started task=consumer")

    # 5. Wait for completion or signal
    try:
        await consumer_task
    except asyncio.CancelledError:
        logger.info("worker_shutdown_requested reason=signal")
    except Exception as e:
        logger.exception(f"worker_error error={str(e)}")
        raise
    finally:
        if redis_client:
            await redis_client.close()
        if rabbitmq_client:
            await rabbitmq_client.close()
        logger.info("worker_shutdown_completed")

if __name__ == "__main__":
    with suppress(asyncio.CancelledError):
        asyncio.run(main())
```

```python
# Example worker task with Redis and RabbitMQ dependency injection
async def process_photo_task(photo_data: dict, redis: RedisClient, rabbitmq: RabbitMQClient) -> None:
    """Process photo with proper Request ID context and Redis/RabbitMQ integration."""
    request_id = generate_request_id("photo_processing", photo_id=photo_data.get("id"))
    set_request_id(request_id)

    logger.info(f"photo_processing_started photo_id={photo_data.get('id')}")

    try:
        # Check idempotency using Redis
        if not await redis.check_idempotency(request_id):
            logger.info(f"duplicate_photo_detected photo_id={photo_data.get('id')}")
            return

        # Process photo logic here
        await process_photo(photo_data)

        # Cache processed photo metadata
        await redis.cache_data(f"photo:{photo_data.get('id')}", photo_data, ttl=3600)

        # Publish processed photo event
        await rabbitmq.publish_photo_processed(photo_data, request_id)

        logger.info(f"photo_processing_completed photo_id={photo_data.get('id')}")
    except Exception as e:
        logger.exception(f"photo_processing_failed photo_id={photo_data.get('id')} error={str(e)}")
        raise
```


### Verification
- How to verify:
  - Check usage of `asyncio.run(main())` for service startup.
  - Ensure all async dependencies are started/stopped in `main()` function.
  - Verify no `FastAPI` or `AIOgram` imports in worker services.
  - Check use of async libraries (`aio-pika`, `asyncpg`, `redis.asyncio`).
  - Ensure proper signal handling for graceful shutdown.
  - Verify `setup_logging()` is called exactly once at the beginning of `main()`.
  - Check Request ID generation and propagation in worker tasks.
  - Ensure configuration is loaded before logging setup.
  - Verify Redis and RabbitMQ clients are initialized once and reused across operations.
  - Ensure Redis and RabbitMQ operations work within the asyncio event loop without conflicts.
  - Follow verification requirements from `testing-standards.mdc` for AsyncIO worker services.
- Success criteria:
  - Worker services start correctly; no event loop conflicts; proper resource cleanup; signal handling implemented; logging properly integrated; Request ID propagation working; Redis and RabbitMQ integration working within asyncio event loop; comprehensive test coverage achieved.

### Changes
- 2025-01-27 v1.3.0: Added RabbitMQ integration rules for asyncio services, dependency injection patterns, event loop compatibility requirements, and updated test fixtures for RabbitMQ compatibility alongside Redis.
- 2025-01-27 v1.2.0: Added Redis integration rules for asyncio services, dependency injection patterns, event loop compatibility requirements, and updated test fixtures for asyncio compatibility.
- 2025-01-27 v1.1.0: Added logging integration requirements, configuration management, testing requirements, and updated examples to be fully compliant with ms-best-practices.mdc and logging_rules.mdc.
- 2025-01-27 v1.0.0: Initial Asyncio rules for Python worker services with event loop isolation and lifecycle management.
