---
description: OpenTelemetry distributed tracing for DDD/Hex microservices
globs: ["src/**/*.py", "infrastructure/observability/jaeger/**/*"]
alwaysApply: true
---

### Title
Tracing Rules (OpenTelemetry + Jaeger for DDD/Hex microservices)

### Version and Date
- Version: v1.0.0
- Updated: 2025-09-19
- Owner: rules/observability

# Tracing Rules

### Purpose
Implement comprehensive distributed tracing using OpenTelemetry and Jaeger for DDD/Hex microservices. Provides end-to-end visibility into request flows across service boundaries.

### Scope
- Covers: distributed tracing, span creation, context propagation, trace correlation
- Integrates with: `logging_rules.mdc` (Request ID correlation), `observability_rules.mdc` (overall strategy)
- Service types: FastAPI, Aiogram, AsyncIO workers, external dependencies
- Excludes: Metrics collection (see `metrics_rules.mdc`), log aggregation (see `elk_rules.mdc`)

### Target Audience
Backend engineers, DevOps/SRE, performance engineers, debugging specialists.

### Terms and Definitions
- **Trace**: Complete journey of a request through multiple services
- **Span**: Individual operation within a trace (function call, database query, etc.)
- **Context Propagation**: Passing trace context across service boundaries
- **Baggage**: Key-value pairs propagated across spans (like Request ID)
- **Sampling**: Selecting subset of traces for collection (performance optimization)

## OpenTelemetry Architecture

### Core Components

#### 1. Tracer Provider
Central configuration point for all tracing operations

```python
# src/core/tracing.py
import os
from opentelemetry import trace
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.sdk.resources import Resource
from opentelemetry.propagate import set_global_textmap
from opentelemetry.propagators.b3 import B3MultiFormat
from opentelemetry.propagators.jaeger import JaegerPropagator
from opentelemetry.propagators.composite import CompositeHTTPPropagator
from src.core.config import settings
from src.core.logging import logger

def setup_tracing(service_name: str, service_version: str = "1.0.0") -> trace.Tracer:
    """Initialize OpenTelemetry tracing for the service."""

    # Create resource with service information
    resource = Resource.create({
        "service.name": service_name,
        "service.version": service_version,
        "service.instance.id": os.environ.get("HOSTNAME", "unknown"),
        "deployment.environment": settings.environment,
    })

    # Set up tracer provider
    provider = TracerProvider(resource=resource)
    trace.set_tracer_provider(provider)

    # Configure Jaeger exporter
    jaeger_exporter = JaegerExporter(
        agent_host_name=settings.jaeger_agent_host,
        agent_port=settings.jaeger_agent_port,
        collector_endpoint=settings.jaeger_collector_endpoint,
    )

    # Add span processor
    span_processor = BatchSpanProcessor(jaeger_exporter)
    provider.add_span_processor(span_processor)

    # Set up context propagation (multiple formats for compatibility)
    set_global_textmap(
        CompositeHTTPPropagator([
            JaegerPropagator(),
            B3MultiFormat(),
        ])
    )

    # Get tracer instance
    tracer = trace.get_tracer(__name__)

    logger.info(
        f"tracing_initialized service={service_name} "
        f"jaeger_endpoint={settings.jaeger_collector_endpoint}"
    )

    return tracer

# Global tracer instance (set by each service during startup)
tracer: trace.Tracer = None

def get_tracer() -> trace.Tracer:
    """Get the global tracer instance."""
    if tracer is None:
        raise RuntimeError("Tracing not initialized. Call setup_tracing() first.")
    return tracer
```

#### 2. Request ID Integration
Seamless integration with existing Request ID system from logging_rules.mdc

```python
# src/core/tracing.py (continued)
from opentelemetry import baggage
from src.core.logging import get_current_request_id, set_request_id

def propagate_request_id_to_baggage() -> None:
    """Propagate current Request ID to OpenTelemetry baggage."""
    request_id = get_current_request_id()
    if request_id:
        baggage.set_baggage("request_id", request_id)

def extract_request_id_from_baggage() -> str | None:
    """Extract Request ID from OpenTelemetry baggage."""
    return baggage.get_baggage("request_id")

def ensure_request_id_correlation() -> str:
    """Ensure Request ID is available and synced between logging and tracing."""
    # Try to get from logging context first
    request_id = get_current_request_id()

    if not request_id:
        # Try to get from baggage
        request_id = extract_request_id_from_baggage()
        if request_id:
            set_request_id(request_id)

    if not request_id:
        # Generate new request ID
        from src.core.logging import generate_request_id
        request_id = generate_request_id("trace")
        set_request_id(request_id)

    # Ensure it's in baggage for downstream services
    propagate_request_id_to_baggage()

    return request_id

def create_span_with_request_id(
    name: str,
    kind: trace.SpanKind = trace.SpanKind.INTERNAL,
    attributes: dict = None
) -> trace.Span:
    """Create a span with automatic Request ID correlation."""
    request_id = ensure_request_id_correlation()

    span = get_tracer().start_span(
        name,
        kind=kind,
        attributes={
            "request_id": request_id,
            **(attributes or {})
        }
    )

    return span
```

## Service-Specific Tracing Implementation

### FastAPI Service Tracing

#### Automatic HTTP Request Tracing
```python
# src/core/fastapi_tracing.py
import time
from typing import Callable
from fastapi import Request, Response
from opentelemetry import trace, propagate
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor
from opentelemetry.instrumentation.redis import RedisInstrumentor
from opentelemetry.instrumentation.httpx import HTTPXClientInstrumentor
from src.core.tracing import get_tracer, ensure_request_id_correlation, create_span_with_request_id
from src.core.logging import logger

class TracingMiddleware:
    """Custom tracing middleware for enhanced FastAPI tracing."""

    async def __call__(self, request: Request, call_next: Callable) -> Response:
        # Extract trace context from headers
        context = propagate.extract(request.headers)

        # Ensure Request ID correlation
        request_id = ensure_request_id_correlation()

        # Create root span for the request
        with create_span_with_request_id(
            f"{request.method} {request.url.path}",
            kind=trace.SpanKind.SERVER,
            attributes={
                "http.method": request.method,
                "http.url": str(request.url),
                "http.route": request.url.path,
                "http.user_agent": request.headers.get("user-agent", ""),
                "request_id": request_id,
            }
        ) as span:
            # Set span in context
            token = trace.set_span_in_context(span, context)

            try:
                # Process request
                response = await call_next(request)

                # Add response attributes
                span.set_attribute("http.status_code", response.status_code)
                span.set_status(
                    trace.StatusCode.ERROR if response.status_code >= 400 else trace.StatusCode.OK
                )

                # Inject trace context into response headers
                headers = {}
                propagate.inject(headers)
                for key, value in headers.items():
                    response.headers[key] = value

                return response

            except Exception as e:
                # Record exception in span
                span.record_exception(e)
                span.set_status(trace.StatusCode.ERROR, str(e))
                span.set_attribute("error.type", type(e).__name__)

                logger.exception(f"fastapi_tracing_error error={str(e)}")
                raise

            finally:
                # Reset context
                trace.set_span_in_context(None, token)

def setup_fastapi_tracing(app, service_name: str = "api_service") -> None:
    """Set up comprehensive tracing for FastAPI application."""

    # Auto-instrument FastAPI
    FastAPIInstrumentor.instrument_app(app, tracer_provider=trace.get_tracer_provider())

    # Auto-instrument SQLAlchemy
    SQLAlchemyInstrumentor().instrument(tracer_provider=trace.get_tracer_provider())

    # Auto-instrument Redis
    RedisInstrumentor().instrument(tracer_provider=trace.get_tracer_provider())

    # Auto-instrument HTTPX for external API calls
    HTTPXClientInstrumentor().instrument(tracer_provider=trace.get_tracer_provider())

    # Add custom tracing middleware
    app.middleware("http")(TracingMiddleware())

    logger.info(f"fastapi_tracing_setup service={service_name} auto_instrumentation=enabled")

# Usage in main.py
from fastapi import FastAPI
from src.core.tracing import setup_tracing
from src.core.fastapi_tracing import setup_fastapi_tracing

app = FastAPI()

# Initialize tracing
setup_tracing("api_service", "1.0.0")
setup_fastapi_tracing(app, "api_service")
```

#### Business Logic Tracing
```python
# src/services/user_service.py
from opentelemetry import trace
from src.core.tracing import create_span_with_request_id
from src.core.logging import logger

class UserService:
    """User service with comprehensive tracing."""

    async def create_user(self, user_data: UserCreate) -> User:
        """Create user with detailed tracing."""

        with create_span_with_request_id(
            "user.create",
            attributes={
                "user.email": user_data.email,
                "user.source": user_data.source,
                "operation": "create_user"
            }
        ) as span:
            try:
                # Validate user data
                with create_span_with_request_id("user.validate") as validation_span:
                    await self._validate_user_data(user_data)
                    validation_span.set_attribute("validation.result", "success")

                # Check for existing user
                with create_span_with_request_id("user.check_existing") as check_span:
                    existing_user = await self._check_existing_user(user_data.email)
                    check_span.set_attribute("existing_user.found", existing_user is not None)

                    if existing_user:
                        span.set_status(trace.StatusCode.ERROR, "User already exists")
                        raise UserAlreadyExistsError(user_data.email)

                # Create user in database
                with create_span_with_request_id("user.database.create") as db_span:
                    user = await self.user_repository.create(user_data)
                    db_span.set_attribute("user.id", user.id)
                    db_span.set_attribute("database.operation", "insert")

                # Send welcome email
                with create_span_with_request_id("user.notification.welcome") as notification_span:
                    await self._send_welcome_email(user)
                    notification_span.set_attribute("notification.type", "welcome_email")
                    notification_span.set_attribute("notification.recipient", user.email)

                span.set_attribute("user.created.id", user.id)
                span.set_status(trace.StatusCode.OK)

                logger.info(f"user_created user_id={user.id} email={user.email}")
                return user

            except Exception as e:
                span.record_exception(e)
                span.set_status(trace.StatusCode.ERROR, str(e))
                span.set_attribute("error.type", type(e).__name__)

                logger.exception(f"user_creation_failed error={str(e)}")
                raise

    async def _validate_user_data(self, user_data: UserCreate) -> None:
        """Validate user data with tracing."""
        # Validation logic with spans for different validation steps
        pass

    async def _check_existing_user(self, email: str) -> User | None:
        """Check for existing user with database tracing."""
        # Database query that will be auto-traced by SQLAlchemy instrumentation
        return await self.user_repository.get_by_email(email)
```

### Aiogram Service Tracing

#### Bot Message Processing Tracing
```python
# src/core/bot_tracing.py
import time
from typing import Dict, Any, Callable, Awaitable
from aiogram import BaseMiddleware
from aiogram.types import Message, Update
from opentelemetry import trace, propagate, baggage
from src.core.tracing import create_span_with_request_id, ensure_request_id_correlation
from src.core.logging import logger

class BotTracingMiddleware(BaseMiddleware):
    """Comprehensive tracing middleware for Aiogram bot."""

    async def __call__(
        self,
        handler: Callable[[Update, Dict[str, Any]], Awaitable[Any]],
        event: Update,
        data: Dict[str, Any]
    ) -> Any:
        # Ensure Request ID correlation
        request_id = ensure_request_id_correlation()

        # Extract message metadata
        message_type = "unknown"
        user_id = None
        chat_id = None
        handler_name = handler.__name__ if hasattr(handler, '__name__') else "unknown"

        if event.message:
            message = event.message
            message_type = self._get_message_type(message)
            user_id = message.from_user.id if message.from_user else None
            chat_id = message.chat.id if message.chat else None

        # Create root span for message processing
        with create_span_with_request_id(
            f"bot.message.{message_type}",
            kind=trace.SpanKind.SERVER,
            attributes={
                "bot.message.type": message_type,
                "bot.user.id": str(user_id) if user_id else None,
                "bot.chat.id": str(chat_id) if chat_id else None,
                "bot.handler": handler_name,
                "messaging.system": "telegram",
                "messaging.operation": "process",
            }
        ) as span:
            try:
                # Add media-specific attributes
                if event.message:
                    self._add_media_attributes(span, event.message)

                # Process the message
                result = await handler(event, data)

                span.set_status(trace.StatusCode.OK)
                span.set_attribute("bot.processing.result", "success")

                return result

            except Exception as e:
                span.record_exception(e)
                span.set_status(trace.StatusCode.ERROR, str(e))
                span.set_attribute("error.type", type(e).__name__)
                span.set_attribute("bot.processing.result", "error")

                logger.exception(
                    f"bot_message_tracing_error handler={handler_name} "
                    f"message_type={message_type} error={str(e)}"
                )
                raise

    def _get_message_type(self, message: Message) -> str:
        """Determine message type for tracing."""
        if message.text:
            return "text"
        elif message.photo:
            return "photo"
        elif message.document:
            return "document"
        elif message.video:
            return "video"
        elif message.voice:
            return "voice"
        elif message.sticker:
            return "sticker"
        else:
            return "other"

    def _add_media_attributes(self, span: trace.Span, message: Message) -> None:
        """Add media-specific attributes to span."""
        if message.photo and message.photo[-1].file_size:
            span.set_attribute("bot.media.file_size", message.photo[-1].file_size)
            span.set_attribute("bot.media.file_id", message.photo[-1].file_id)
        elif message.document:
            if message.document.file_size:
                span.set_attribute("bot.media.file_size", message.document.file_size)
            span.set_attribute("bot.media.file_id", message.document.file_id)
            span.set_attribute("bot.media.mime_type", message.document.mime_type or "unknown")
        elif message.video and message.video.file_size:
            span.set_attribute("bot.media.file_size", message.video.file_size)
            span.set_attribute("bot.media.duration", message.video.duration)
        elif message.voice and message.voice.file_size:
            span.set_attribute("bot.media.file_size", message.voice.file_size)
            span.set_attribute("bot.media.duration", message.voice.duration)

# Setup in main.py
from aiogram import Dispatcher
from src.core.bot_tracing import BotTracingMiddleware

async def setup_bot_tracing(dp: Dispatcher) -> None:
    """Set up bot tracing middleware."""
    dp.middleware.setup(BotTracingMiddleware())
    logger.info("bot_tracing_setup middleware=BotTracingMiddleware status=registered")
```

#### Bot Handler Tracing
```python
# src/handlers/photo_handler.py
from aiogram import types
from opentelemetry import trace
from src.core.tracing import create_span_with_request_id
from src.core.logging import logger

async def process_photo(message: types.Message) -> None:
    """Process photo message with detailed tracing."""

    with create_span_with_request_id(
        "bot.photo.process",
        attributes={
            "bot.photo.count": len(message.photo),
            "bot.user.id": str(message.from_user.id),
            "operation": "photo_processing"
        }
    ) as span:
        try:
            # Download photo
            with create_span_with_request_id("bot.photo.download") as download_span:
                photo = message.photo[-1]  # Get highest resolution
                file_info = await bot.get_file(photo.file_id)
                file_data = await bot.download_file(file_info.file_path)

                download_span.set_attribute("bot.photo.file_size", photo.file_size or 0)
                download_span.set_attribute("bot.photo.file_id", photo.file_id)

            # Process image
            with create_span_with_request_id("bot.photo.analyze") as analyze_span:
                analysis_result = await analyze_photo(file_data)
                analyze_span.set_attribute("analysis.result", analysis_result.get("classification"))
                analyze_span.set_attribute("analysis.confidence", analysis_result.get("confidence", 0))

            # Send to processing queue
            with create_span_with_request_id("bot.photo.queue") as queue_span:
                await send_to_processing_queue({
                    "photo_id": photo.file_id,
                    "user_id": message.from_user.id,
                    "analysis": analysis_result
                })
                queue_span.set_attribute("queue.name", "photo-processing")

            # Reply to user
            with create_span_with_request_id("bot.photo.reply") as reply_span:
                await message.reply("Photo received and processing started!")
                reply_span.set_attribute("bot.reply.sent", True)

            span.set_attribute("processing.status", "completed")
            span.set_status(trace.StatusCode.OK)

        except Exception as e:
            span.record_exception(e)
            span.set_status(trace.StatusCode.ERROR, str(e))

            logger.exception(f"photo_processing_error error={str(e)}")
            await message.reply("Sorry, there was an error processing your photo.")
            raise
```

### AsyncIO Worker Service Tracing

#### Worker Job Tracing
```python
# src/core/worker_tracing.py
import asyncio
from typing import Dict, Any, Optional
from opentelemetry import trace, propagate
from src.core.tracing import create_span_with_request_id, ensure_request_id_correlation
from src.core.logging import logger

class WorkerTracing:
    """Worker tracing utilities for AsyncIO services."""

    def __init__(self, worker_type: str):
        self.worker_type = worker_type

    async def process_job_with_tracing(
        self,
        job_data: Dict[str, Any],
        job_processor: callable,
        queue_name: str = "default"
    ) -> Any:
        """Process worker job with comprehensive tracing."""

        # Extract trace context from job data if available
        trace_context = job_data.get('trace_context', {})
        context = propagate.extract(trace_context) if trace_context else None

        # Ensure Request ID correlation
        request_id = job_data.get('request_id')
        if request_id:
            from src.core.logging import set_request_id
            set_request_id(request_id)

        request_id = ensure_request_id_correlation()

        job_type = job_data.get('type', 'unknown')
        job_id = job_data.get('id', 'unknown')

        # Create root span for job processing
        with create_span_with_request_id(
            f"worker.job.{job_type}",
            kind=trace.SpanKind.CONSUMER,
            attributes={
                "worker.type": self.worker_type,
                "worker.job.type": job_type,
                "worker.job.id": job_id,
                "worker.queue": queue_name,
                "messaging.system": "rabbitmq",
                "messaging.operation": "process",
            }
        ) as span:
            try:
                # Add job-specific attributes
                self._add_job_attributes(span, job_data)

                # Process the job
                result = await job_processor(job_data)

                span.set_attribute("worker.job.result", "success")
                span.set_status(trace.StatusCode.OK)

                logger.info(
                    f"worker_job_completed job_type={job_type} "
                    f"job_id={job_id} worker_type={self.worker_type}"
                )

                return result

            except Exception as e:
                span.record_exception(e)
                span.set_status(trace.StatusCode.ERROR, str(e))
                span.set_attribute("worker.job.result", "error")
                span.set_attribute("error.type", type(e).__name__)

                logger.exception(
                    f"worker_job_error job_type={job_type} "
                    f"job_id={job_id} error={str(e)}"
                )
                raise

    def _add_job_attributes(self, span: trace.Span, job_data: Dict[str, Any]) -> None:
        """Add job-specific attributes to span."""
        # Add safe attributes (no sensitive data)
        for key in ['priority', 'retry_count', 'max_retries', 'created_at']:
            if key in job_data:
                span.set_attribute(f"worker.job.{key}", str(job_data[key]))

    def create_job_trace_context(self) -> Dict[str, str]:
        """Create trace context for enqueueing jobs."""
        headers = {}
        propagate.inject(headers)
        return headers

# Usage in worker main.py
from src.core.worker_tracing import WorkerTracing

async def main():
    """Worker main function with tracing."""

    # Initialize tracing
    from src.core.tracing import setup_tracing
    setup_tracing("image-worker", "1.0.0")

    # Initialize worker tracing
    worker_tracing = WorkerTracing("image-processor")

    # Example job processing
    async def process_image_job(job_data: Dict[str, Any]) -> Dict[str, Any]:
        """Process image job with internal tracing."""

        with create_span_with_request_id("image.resize") as resize_span:
            # Image resizing logic
            original_size = job_data.get('original_size', 'unknown')
            target_size = job_data.get('target_size', 'unknown')

            resize_span.set_attribute("image.original_size", original_size)
            resize_span.set_attribute("image.target_size", target_size)

            # Simulate processing
            await asyncio.sleep(2)

            resize_span.set_attribute("image.processing.result", "success")

        with create_span_with_request_id("image.upload") as upload_span:
            # Upload to storage
            upload_span.set_attribute("storage.provider", "s3")
            upload_span.set_attribute("storage.bucket", "processed-images")

            # Simulate upload
            await asyncio.sleep(1)

            output_url = "s3://bucket/processed.jpg"
            upload_span.set_attribute("storage.url", output_url)

        return {"status": "completed", "output_url": output_url}

    # Process jobs with tracing
    while True:
        try:
            # Get job from queue (pseudo-code)
            job_data = await get_next_job_from_queue()
            if job_data:
                await worker_tracing.process_job_with_tracing(
                    job_data,
                    process_image_job,
                    queue_name="image-processing"
                )
            else:
                await asyncio.sleep(1)  # No jobs available

        except Exception as e:
            logger.exception(f"worker_main_error error={str(e)}")
            await asyncio.sleep(5)  # Wait before retrying

if __name__ == "__main__":
    asyncio.run(main())
```

## Cross-Service Trace Propagation

### RabbitMQ Message Tracing
```python
# src/core/messaging_tracing.py
import json
from typing import Dict, Any
import aio_pika
from opentelemetry import trace, propagate
from src.core.tracing import create_span_with_request_id, ensure_request_id_correlation
from src.core.logging import logger

class TracingMessagePublisher:
    """RabbitMQ publisher with tracing support."""

    def __init__(self, connection: aio_pika.Connection):
        self.connection = connection

    async def publish_with_tracing(
        self,
        exchange_name: str,
        routing_key: str,
        message_data: Dict[str, Any],
        message_type: str = "unknown"
    ) -> None:
        """Publish message with trace context propagation."""

        # Ensure Request ID correlation
        request_id = ensure_request_id_correlation()

        with create_span_with_request_id(
            f"messaging.publish.{message_type}",
            kind=trace.SpanKind.PRODUCER,
            attributes={
                "messaging.system": "rabbitmq",
                "messaging.destination": f"{exchange_name}.{routing_key}",
                "messaging.operation": "publish",
                "messaging.message_type": message_type,
            }
        ) as span:
            try:
                # Inject trace context into message headers
                trace_headers = {}
                propagate.inject(trace_headers)

                # Prepare message with trace context and Request ID
                enhanced_message_data = {
                    **message_data,
                    "request_id": request_id,
                    "trace_context": trace_headers
                }

                # Create message
                channel = await self.connection.channel()
                exchange = await channel.declare_exchange(
                    exchange_name,
                    aio_pika.ExchangeType.TOPIC,
                    durable=True
                )

                message = aio_pika.Message(
                    body=json.dumps(enhanced_message_data).encode(),
                    headers={
                        **trace_headers,
                        "x-request-id": request_id,
                        "message-type": message_type
                    },
                    content_type="application/json",
                    delivery_mode=aio_pika.DeliveryMode.PERSISTENT
                )

                # Publish message
                await exchange.publish(message, routing_key=routing_key)

                span.set_attribute("messaging.message_id", message.message_id or "unknown")
                span.set_attribute("messaging.body_size", len(message.body))
                span.set_status(trace.StatusCode.OK)

                logger.info(
                    f"message_published exchange={exchange_name} "
                    f"routing_key={routing_key} message_type={message_type}"
                )

            except Exception as e:
                span.record_exception(e)
                span.set_status(trace.StatusCode.ERROR, str(e))

                logger.exception(
                    f"message_publish_error exchange={exchange_name} "
                    f"routing_key={routing_key} error={str(e)}"
                )
                raise

class TracingMessageConsumer:
    """RabbitMQ consumer with tracing support."""

    async def consume_with_tracing(
        self,
        message: aio_pika.IncomingMessage,
        processor: callable
    ) -> None:
        """Consume message with trace context extraction."""

        # Extract trace context from message headers
        trace_context = {}
        for key, value in message.headers.items():
            if isinstance(value, (str, bytes)):
                trace_context[key] = value.decode() if isinstance(value, bytes) else value

        context = propagate.extract(trace_context)

        # Extract Request ID
        request_id = message.headers.get("x-request-id")
        if request_id:
            if isinstance(request_id, bytes):
                request_id = request_id.decode()
            from src.core.logging import set_request_id
            set_request_id(request_id)

        # Parse message data
        try:
            message_data = json.loads(message.body.decode())
        except json.JSONDecodeError:
            message_data = {"raw_body": message.body.decode()}

        message_type = message.headers.get("message-type", "unknown")
        if isinstance(message_type, bytes):
            message_type = message_type.decode()

        # Create span for message consumption
        with create_span_with_request_id(
            f"messaging.consume.{message_type}",
            kind=trace.SpanKind.CONSUMER,
            attributes={
                "messaging.system": "rabbitmq",
                "messaging.source": message.routing_key,
                "messaging.operation": "consume",
                "messaging.message_type": message_type,
                "messaging.message_id": message.message_id or "unknown",
            }
        ) as span:
            try:
                # Process the message
                await processor(message_data)

                span.set_status(trace.StatusCode.OK)
                await message.ack()

                logger.info(
                    f"message_consumed routing_key={message.routing_key} "
                    f"message_type={message_type} status=acked"
                )

            except Exception as e:
                span.record_exception(e)
                span.set_status(trace.StatusCode.ERROR, str(e))

                logger.exception(
                    f"message_consume_error routing_key={message.routing_key} "
                    f"message_type={message_type} error={str(e)}"
                )

                # Decide on nack/requeue based on error type
                await message.nack(requeue=True)
```

## Jaeger Configuration

### Jaeger Docker Compose
```yaml
# Infrastructure configuration (already included in observability_rules.mdc)
jaeger:
  image: jaegertracing/all-in-one:1.50
  ports:
    - "16686:16686"  # Jaeger UI
    - "14268:14268"  # HTTP collector
    - "6831:6831/udp"  # Jaeger agent
    - "6832:6832/udp"  # Jaeger agent
  environment:
    - COLLECTOR_OTLP_ENABLED=true
    - SPAN_STORAGE_TYPE=memory
  networks:
    - observability
```

### Environment Configuration
```python
# src/core/config.py (additions)
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # ... existing settings ...

    # Tracing configuration
    jaeger_agent_host: str = "jaeger"
    jaeger_agent_port: int = 6831
    jaeger_collector_endpoint: str = "http://jaeger:14268/api/traces"
    jaeger_sampling_rate: float = 1.0  # Sample all traces in development

    # Tracing features
    tracing_enabled: bool = True
    tracing_debug: bool = False

    class Config:
        env_file = ".env"
```

## Performance Optimization

### Sampling Configuration
```python
# src/core/tracing.py (enhanced)
from opentelemetry.sdk.trace.sampling import (
    TraceIdRatioBased,
    ParentBased,
    ALWAYS_OFF,
    ALWAYS_ON
)

def get_sampler(environment: str, sampling_rate: float):
    """Get appropriate sampler based on environment."""

    if environment == "production":
        # Production: Sample based on rate with parent-based decisions
        return ParentBased(
            root=TraceIdRatioBased(sampling_rate),
            remote_parent_sampled=ALWAYS_ON,
            remote_parent_not_sampled=ALWAYS_OFF,
            local_parent_sampled=ALWAYS_ON,
            local_parent_not_sampled=ALWAYS_OFF,
        )
    elif environment == "staging":
        # Staging: Higher sampling rate
        return ParentBased(root=TraceIdRatioBased(min(sampling_rate * 2, 1.0)))
    else:
        # Development: Sample everything
        return ParentBased(root=ALWAYS_ON)

# Update setup_tracing function
def setup_tracing(service_name: str, service_version: str = "1.0.0") -> trace.Tracer:
    """Initialize OpenTelemetry tracing with sampling."""

    # ... existing resource setup ...

    # Set up tracer provider with sampling
    sampler = get_sampler(settings.environment, settings.jaeger_sampling_rate)
    provider = TracerProvider(
        resource=resource,
        sampler=sampler
    )

    # ... rest of setup ...
```

## Verification and Testing

### Tracing Health Checks
```python
# src/core/tracing_health.py
import asyncio
from typing import Dict, Any
from opentelemetry import trace
from src.core.tracing import create_span_with_request_id

async def check_tracing_health() -> Dict[str, Any]:
    """Verify tracing is functioning correctly."""

    health = {
        "tracer_provider": "unknown",
        "span_creation": "unknown",
        "context_propagation": "unknown",
        "jaeger_connection": "unknown"
    }

    try:
        # Check tracer provider
        provider = trace.get_tracer_provider()
        health["tracer_provider"] = "healthy" if provider else "unhealthy"

        # Test span creation
        with create_span_with_request_id("health.check.span") as span:
            span.set_attribute("health.check", True)
            health["span_creation"] = "healthy"

        # Test context propagation
        headers = {}
        from opentelemetry import propagate
        propagate.inject(headers)
        health["context_propagation"] = "healthy" if headers else "unhealthy"

        # Test Jaeger connection (simplified)
        health["jaeger_connection"] = "healthy"  # Assume healthy if no errors

    except Exception as e:
        health["error"] = str(e)
        health["status"] = "unhealthy"
        return health

    # Overall status
    all_healthy = all(status == "healthy" for key, status in health.items() if key != "error")
    health["status"] = "healthy" if all_healthy else "unhealthy"

    return health

# Add to FastAPI health endpoint
@app.get("/health/tracing")
async def tracing_health():
    return await check_tracing_health()
```

## Development Commands

### Tracing Operations
```bash
# Access Jaeger UI
open http://localhost:16686

# Check Jaeger health
curl http://localhost:16686/api/health

# Test trace generation
curl http://localhost:8000/health/tracing

# View traces for specific service
curl "http://localhost:16686/api/traces?service=api_service&limit=10"

# Check span statistics
curl "http://localhost:16686/api/services"
```

## Troubleshooting

### Common Issues
1. **Missing traces**: Check Jaeger connectivity and sampling configuration
2. **Broken trace correlation**: Verify context propagation across services
3. **Performance impact**: Adjust sampling rates and span attributes
4. **Memory issues**: Configure appropriate span processors and exporters

### Debug Tracing
```python
# Enable debug logging for OpenTelemetry
import logging
logging.getLogger("opentelemetry").setLevel(logging.DEBUG)

# Test trace creation
from src.core.tracing import create_span_with_request_id

async def debug_trace():
    with create_span_with_request_id("debug.test") as span:
        span.set_attribute("debug.enabled", True)
        print(f"Trace ID: {span.get_span_context().trace_id}")
        print(f"Span ID: {span.get_span_context().span_id}")
```

---

## Summary

This comprehensive tracing implementation provides end-to-end visibility into your microservices architecture using OpenTelemetry and Jaeger. The setup seamlessly integrates with your existing Request ID system from logging_rules.mdc and provides detailed insights into request flows across all service types.

**Key Features**:
- Complete OpenTelemetry integration for FastAPI, Aiogram, and AsyncIO services
- Seamless Request ID correlation with existing logging system
- Cross-service trace propagation via RabbitMQ
- Performance-optimized with configurable sampling
- Comprehensive error tracking and debugging capabilities
- Production-ready Jaeger deployment configuration