---
description: Data access layer rules for PostgreSQL and MongoDB services; defines patterns for centralized database operations, HTTP-based data access, and service integration in the Improved Hybrid Approach architecture.
globs: ["services/db-*/**/*.py", "services/*/src/**/*.py"]
alwaysApply: true
---

### Title
Data Access Layer Rules (Improved Hybrid Approach)

### Version and Date
- Version: v1.0.0
- Updated: 2025-09-20
- Owner: rules/architecture
- ADR link (optional):

### Purpose
Define comprehensive rules for implementing the Improved Hybrid Approach architecture with centralized data access services for PostgreSQL and MongoDB, ensuring clean separation between data access and business logic while maintaining performance and consistency.

### Scope
- Covers: data service architecture, HTTP-based data access patterns, schema design, error handling, performance optimization, and service integration.
- Excludes: general microservice practices (see `ms_best_practices_rules.mdc`) and database-specific optimizations.

### Terms and Definitions
- **Data Service**: Centralized service responsible for database operations (db_postgres_service, db_mongo_service).
- **Business Service**: Service containing business logic that accesses data via HTTP (api_service, bot_service, worker_service).
- **Data Client**: HTTP client used by business services to communicate with data services.
- **Repository Pattern**: Data access abstraction within data services.
- **Domain-Aware Operations**: Data service methods that understand business context.

### Rules

1) **Data Service Architecture**
   - **MUST:** Implement data services as separate, dedicated FastAPI applications.
   - **MUST:** Follow single responsibility principle - each data service owns one database type (PostgreSQL or MongoDB).
   - **MUST:** Expose only HTTP APIs - no direct database access from business services.
   - **MUST:** Implement both generic CRUD operations and domain-specific methods.
   - **SHOULD:** Use repository pattern within data services for data access abstraction.
   - **SHOULD:** Implement connection pooling and performance optimizations within data services.

2) **PostgreSQL Data Service (db_postgres_service)**
   - **MUST:** Use SQLAlchemy 2.x with async support for all database operations.
   - **MUST:** Implement proper transaction management with rollback on errors.
   - **MUST:** Use repository pattern for data access with clear interface boundaries.
   - **MUST:** Provide endpoints for: Users, Products, Orders, Payments, and related entities.
   - **MUST:** Support pagination, filtering, and sorting for all list operations.
   - **MUST:** Implement proper SQL injection protection via parameterized queries.
   - **SHOULD:** Use database migrations (Alembic) for schema changes.
   - **SHOULD:** Implement database connection health checks.

3) **MongoDB Data Service (db_mongo_service)**
   - **MUST:** Use Motor (async MongoDB driver) for all database operations.
   - **MUST:** Implement proper document validation using Pydantic schemas.
   - **MUST:** Use repository pattern with MongoDB-specific operations.
   - **MUST:** Provide endpoints for: Analytics Events, User Behavior, Logs, and document storage.
   - **MUST:** Support aggregation pipelines for complex analytics queries.
   - **MUST:** Implement proper index management for performance.
   - **SHOULD:** Use MongoDB's built-in validation features.
   - **SHOULD:** Implement document-level security and access patterns.

4) **Business Service Integration**
   - **MUST:** Access data ONLY via HTTP calls to data services - no direct database connections.
   - **MUST:** Use async HTTP clients (httpx) for all data service communication.
   - **MUST:** Implement proper error handling for HTTP communication (timeouts, retries, circuit breakers).
   - **MUST:** Handle HTTP status codes appropriately (404 for not found, 409 for conflicts, etc.).
   - **MUST:** Pass request context (request_id, user_id) to data services for tracing.
   - **SHOULD:** Implement caching strategies for frequently accessed data.
   - **SHOULD:** Use dependency injection for data service clients.

5) **API Design Patterns**
   - **MUST:** Version all data service APIs with `/api/v1` prefix.
   - **MUST:** Use consistent HTTP status codes across all data services.
   - **MUST:** Implement proper OpenAPI documentation for all endpoints.
   - **MUST:** Use Pydantic models for request/response validation.
   - **MUST:** Provide health check endpoints (`/health`, `/ready`) for each data service.
   - **SHOULD:** Use consistent naming conventions across all endpoints.
   - **SHOULD:** Implement rate limiting for data service endpoints.

6) **Error Handling and Resilience**
   - **MUST:** Return structured error responses using RFC 7807 Problem Details format.
   - **MUST:** Implement proper HTTP error mapping (400 for validation, 500 for server errors).
   - **MUST:** Log all errors with appropriate context and request correlation.
   - **MUST:** Implement graceful degradation when data services are unavailable.
   - **SHOULD:** Use circuit breaker pattern for data service communication.
   - **SHOULD:** Implement retry logic with exponential backoff for transient failures.

7) **Performance and Optimization**
   - **MUST:** Implement connection pooling in data services.
   - **MUST:** Use appropriate database indexes for common query patterns.
   - **MUST:** Implement pagination for all list operations to prevent large result sets.
   - **MUST:** Set reasonable timeouts for all HTTP operations.
   - **SHOULD:** Implement caching at appropriate layers (Redis, application-level).
   - **SHOULD:** Use database query optimization techniques.
   - **SHOULD:** Monitor and log performance metrics for all operations.

8) **Security and Access Control**
   - **MUST:** Validate all input data using Pydantic schemas.
   - **MUST:** Implement proper authentication and authorization checks.
   - **MUST:** Sanitize all database queries to prevent injection attacks.
   - **MUST:** Use environment variables for all sensitive configuration.
   - **SHOULD:** Implement request rate limiting and throttling.
   - **SHOULD:** Use HTTPS for all inter-service communication in production.

9) **Observability and Monitoring**
   - **MUST:** Implement structured logging with request correlation across services.
   - **MUST:** Expose Prometheus metrics for all data operations.
   - **MUST:** Implement distributed tracing with OpenTelemetry.
   - **MUST:** Monitor database connection health and performance.
   - **SHOULD:** Implement alerting for critical errors and performance degradation.
   - **SHOULD:** Use centralized logging for all data access operations.

10) **Testing Strategies**
    - **MUST:** Write unit tests for all repository classes and business logic.
    - **MUST:** Write integration tests using real databases (via testcontainers).
    - **MUST:** Test HTTP integration between business and data services.
    - **MUST:** Mock data service HTTP calls in business service unit tests.
    - **SHOULD:** Implement contract testing between services.
    - **SHOULD:** Use load testing for performance validation.

### Examples

```python
# Example: PostgreSQL Data Service Repository
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

class UserRepository:
    def __init__(self, db: AsyncSession):
        self.db = db

    async def create_user(self, user_data: UserCreate) -> User:
        """Create a new user with transaction management."""
        user = User(**user_data.model_dump())
        self.db.add(user)
        await self.db.commit()
        await self.db.refresh(user)
        return user

    async def get_user_with_profile(self, user_id: uuid.UUID) -> Optional[UserWithProfile]:
        """Domain-aware operation combining user and profile data."""
        stmt = select(User).options(selectinload(User.profile)).where(User.id == user_id)
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()
```

```python
# Example: MongoDB Data Service Repository
from src.db.database import MongoDBRepository

class AnalyticsRepository(MongoDBRepository):
    def __init__(self):
        super().__init__("analytics_events")

    async def create_event(self, event_data: AnalyticsEventCreate) -> str:
        """Create analytics event with timestamp."""
        event_dict = event_data.model_dump()
        event_dict["created_at"] = datetime.utcnow()
        return await self.create_one(event_dict)

    async def get_user_events_summary(self, user_id: str, days: int = 30) -> dict:
        """Domain-aware aggregation for user event summary."""
        cutoff_date = datetime.utcnow() - timedelta(days=days)
        pipeline = [
            {"$match": {"user_id": user_id, "timestamp": {"$gte": cutoff_date}}},
            {"$group": {
                "_id": "$event_type",
                "count": {"$sum": 1},
                "last_event": {"$max": "$timestamp"}
            }}
        ]
        return await self.aggregate(pipeline)
```

```python
# Example: Business Service Data Client
import httpx
from typing import Optional

class UserDataClient:
    def __init__(self, base_url: str):
        self.base_url = base_url

    async def get_user(self, user_id: str, request_id: str) -> Optional[dict]:
        """Get user from PostgreSQL data service."""
        async with httpx.AsyncClient() as client:
            try:
                response = await client.get(
                    f"{self.base_url}/api/v1/users/{user_id}",
                    headers={"X-Request-ID": request_id},
                    timeout=30.0
                )

                if response.status_code == 404:
                    return None

                response.raise_for_status()
                return response.json()

            except httpx.TimeoutException:
                logger.error(f"Timeout getting user {user_id}")
                raise DataServiceTimeoutError(f"User service timeout: {user_id}")
            except httpx.HTTPStatusError as e:
                logger.error(f"HTTP error getting user {user_id}: {e}")
                raise DataServiceError(f"User service error: {e.response.status_code}")

    async def create_user(self, user_data: dict, request_id: str) -> dict:
        """Create user via PostgreSQL data service."""
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.base_url}/api/v1/users",
                json=user_data,
                headers={"X-Request-ID": request_id},
                timeout=30.0
            )
            response.raise_for_status()
            return response.json()
```

```python
# Example: Business Service Integration
from fastapi import Depends

async def get_user_data_client() -> UserDataClient:
    """Dependency injection for user data client."""
    return UserDataClient(settings.db_postgres_service_url)

class UserService:
    def __init__(self, user_client: UserDataClient, analytics_client: AnalyticsDataClient):
        self.user_client = user_client
        self.analytics_client = analytics_client

    async def register_user(self, user_data: UserCreate, request_id: str) -> UserResponse:
        """Business logic orchestration using data clients."""
        # Create user via PostgreSQL service
        user = await self.user_client.create_user(
            user_data.model_dump(),
            request_id
        )

        # Track registration event via MongoDB service
        await self.analytics_client.track_event({
            "user_id": user["id"],
            "event_type": "user_registration",
            "event_category": "account",
            "event_action": "register"
        }, request_id)

        # Business logic: send welcome email, etc.
        await self._send_welcome_email(user["email"])

        return UserResponse(**user)
```

### Service Ports and URLs
- **PostgreSQL Data Service**: `http://db_postgres_service:8000` (external: `localhost:8001`)
- **MongoDB Data Service**: `http://db_mongo_service:8000` (external: `localhost:8002`)
- **Business Services**: Access data services via internal Docker network URLs

### Verification
- How to verify:
  - Run: `docker-compose up db_postgres_service db_mongo_service`
  - Test: `curl http://localhost:8001/health` and `curl http://localhost:8002/health`
  - Verify: Business services can only access databases via HTTP (no direct DB connections)
  - Check: All HTTP calls include proper error handling and timeouts
  - Validate: OpenAPI documentation available at `/docs` endpoints
- Success criteria:
  - All database access goes through data services
  - HTTP communication includes proper error handling
  - Data services pass health checks
  - Business services have no direct database dependencies

### Changes
- 2025-09-20 v1.0.0: Initial file defining Improved Hybrid Approach patterns for centralized data access services.